#!/usr/bin/env python
"""
    %prog run is2n
"""

import sys
from sys import stderr
import os
import numpy
from numpy import sqrt, array

import fitsio
import lensing
import nsim

import time

from optparse import OptionParser
parser=OptionParser(__doc__)

parser.add_option('--skip',default=None,
                  help="is2n elements to skip")
parser.add_option('--pqr-cov',action='store_true',
                  help="use the pqr covariance (effectively assuming no ring)")

parser.add_option('--jackknife',action='store_true',
                  help="use jackknife errors")
parser.add_option('--chunksize',default=1,
                  help="jackknife chunk size, number of pairs")
parser.add_option('--progress',action='store_true',
                  help="show progress during jackknifing")




CHUNKSIZE=1000000

simple_models=['exp','dev','gauss']

def get_dtype(fobj, model):

    data = fobj[1][0:10]

    names=data.dtype.names

    dt =data.dtype.descr
    dt += [('s2n_matched','f8'),
           ('nsum','i8'),
           ('g_sum','f8',2),
           ('shear_cov','f8',(2,2)),
           ('shear_cov_inv_sum','f8',(2,2)),
           ('P_sum','f8'),
           ('Q_sum','f8',2),
           ('Cinv_sum','f8',(2,2)),
           ('shear','f8',2)]


    if 'gsens' in data.dtype.names:
        dt += [('gsens_sum','f8',2),
               ('shear_lensfit','f8',2),
               ('shear_lensfit_cov','f8',(2,2)),
               ('shear_lensfit_cov_inv_sum','f8',(2,2)),
              ]


    if model in simple_models or model =='bdf':
        dt += [('flux_sum','f8'),
               ('flux_err2invsum','f8'),
               ('flux_s2n_sum','f8'),
               ('flux','f8'),
               ('flux_err','f8'),
               ('flux_s2n','f8'),

               ('T_sum','f8'),
               ('T_err2invsum','f8'),
               ('T_s2n_sum','f8'),
               ('T','f8'),
               ('T_err','f8'),
               ('T_s2n','f8')]

    return dt

def get_chunk_info(nrows):
    nchunks=nrows//CHUNKSIZE

    remain = nrows % CHUNKSIZE
    if remain > 0:
        nchunks += 1

    return nchunks

def get_shear_stats(conf, data, options, g1i=2, g2i=3):

    P_sum, Q_sum, Cinv_sum = lensing.pqr.get_pqr_sums(data['P'],
                                                      data['Q'],
                                                      data['R'])


    if options.jackknife:
        t0=time.time()
        print >>stderr,'jackknifing'

        npair=data.size/2
        chunksize = npair/1000
        #if chunksize > 100:
        #    chunksize=100
        #else:
        #    chunksize=1

        if chunksize < 1:
            chunksize=1
        elif chunksize > 100:
            chunksize=100
        print >>stderr,'    jackknife chunksize:',chunksize

        shear, shear_cov = \
                lensing.pqr.pqr_jackknife(data['P'],data['Q'],data['R'],
                                          progress=options.progress,
                                          chunksize=chunksize,
                                          eps=conf['eps'])

        tm=time.time()-t0
        print 'time to jackknife:',tm/60.,'minutes'

        shear_cov_inv = numpy.linalg.inv(shear_cov)
        w=numpy.arange(data.size)

    elif options.pqr_cov:
        # no ring
        shear_cov_inv = Cinv_sum.copy()
        w=numpy.arange(data.size)
    else:
        names=data.dtype.names
        if 'g_cov' in names:
            cov = data['g_cov']
        else:
            cov = data['pcov'][:,g1i:g1i+2, g1i:g1i+2]

        cov_inv = cov

        det = cov[:,0,0]*cov[:,1,1] - cov[:,0,1]*cov[:,1,0]
        cov_inv[:,0,0] = cov[:,1,1]
        cov_inv[:,1,1] = cov[:,0,0]
        cov_inv[:,0,1] = - cov[:,0,1]
        cov_inv[:,1,0] = - cov[:,1,0]

        w,=numpy.where( det > 0 )
        idet = numpy.zeros(det.size)
        idet[w] = 1.0/det[w]
        cov_inv[:,0,0] *= idet
        cov_inv[:,0,1] *= idet
        cov_inv[:,1,0] *= idet
        cov_inv[:,1,1] *= idet

        shear_cov_inv = cov_inv.sum(axis=0)

    return P_sum, Q_sum, Cinv_sum, shear_cov_inv, w


def add_more_sums(conf, data, d, w, g1i=2, g2i=3):

    model=conf['fit_model']
    T_i = g2i+1
    flux_i = T_i+1

    names=data.dtype.names
    if 'g' in names:
        d['g_sum'][0] += data['g'].sum(axis=0)
    else:
        d['g_sum'][0] += data['pars'][:,g1i:g1i+2].sum(axis=0)

    if 'gsens' in names:
        d['gsens_sum'] = data['gsens'].sum(axis=0)

    if model in simple_models or model=='bdf':
        flux     = data['pars'][:,flux_i:].sum(axis=1)
        flux_var = data['pcov'][:,flux_i:,flux_i:].sum(axis=1).sum(axis=1)

        flux_err = sqrt(flux_var)

        d['flux_sum'][0]        += flux.sum()

        d['flux_err2invsum'][0] += (1.0/flux_var[w]).sum()

        flux_s2n_vals = flux/flux_err
        d['flux_s2n_sum'][0] += flux_s2n_vals.sum()

        T=data['pars'][:,T_i]
        T_var=data['pcov'][:,T_i,T_i]
        T_err=sqrt(T_var)

        # these are for getting the overall mean T not the mean
        # s2n; that is below
        d['T_sum'][0] += T.sum()
        d['T_err2invsum'][0] += (1.0/T_var[w]).sum()

        T_s2n_vals = T/T_err
        d['T_s2n_sum'][0] += T_s2n_vals.sum()

def do_sums(conf, data, d, options):

    g1i=2
    g2i=3

    P_sum, Q_sum, Cinv_sum, shear_cov_inv, w = \
            get_shear_stats(conf, data, options, g1i=g1i, g2i=g2i)

    d['nsum'][0] += data.size
    d['P_sum'][0] += P_sum
    d['Q_sum'][0] += Q_sum
    d['Cinv_sum'][0] += Cinv_sum
    d['shear_cov_inv_sum'][0,:,:] += shear_cov_inv

    add_more_sums(conf, data, d, w, g1i=g1i, g2i=g2i)

def do_avg(conf, d):

    model=conf['fit_model']

    shear_cov = numpy.linalg.inv(d['shear_cov_inv_sum'][0,:,:])

    C = numpy.linalg.inv(d['Cinv_sum'][0,:,:])
    Q_sum = d['Q_sum'][0,:]
    shear = numpy.dot(C,Q_sum)


    # did we expand around the true shear?
    expand_shear=conf.get('expand_shear_true',False)
    if expand_shear:
        true_shear = numpy.array( conf['simc']['shear'] )
        print >>stderr,'adding expand shear:',true_shear
        shear += true_shear

    d['shear'][0] = shear

    sherr=numpy.sqrt(shear_cov[0,0])
    fracdiff=shear[0]/conf['simc']['shear'][0]-1.0
    fracdiff_err=sherr/conf['simc']['shear'][0]
    print >>stderr,'fracdiff:          % .2e +/- %.2e' % (fracdiff, fracdiff_err)

    d['shear_cov'][0,:,:] = shear_cov

    if 'gsens_sum' in d.dtype.names:
        gmean = d['g_sum'][0]/d['nsum']
        gsens = d['gsens_sum'][0]/d['nsum']
        
        shl_cov = shear_cov.copy()
        shl_cov[0,0] /= (gsens[0]*gsens[0])
        shl_cov[0,1] /= (gsens[0]*gsens[1])
        shl_cov[1,0] /= (gsens[0]*gsens[1])
        shl_cov[1,1] /= (gsens[1]*gsens[1])
        shl_cov_inv = numpy.linalg.inv(shl_cov)

        shl =gmean/gsens
        sherr=numpy.sqrt(shl_cov[0,0])

        d['gsens'] = gsens
        d['shear_lensfit'] = shl
        d['shear_lensfit_cov'][0,:,:] = shl_cov
        d['shear_lensfit_cov_inv_sum'][0,:,:] = shl_cov_inv

        fracdiff=shl[0]/conf['simc']['shear'][0]-1.0
        fracdiff_err=sherr/conf['simc']['shear'][0]
        print >>stderr,'fracdiff(lensfit): % .2e +/- %.2e' % (fracdiff, fracdiff_err)

    if model in simple_models or model=='bdf':
        d['flux'] = d['flux_sum']/d['nsum']
        d['flux_err'] = sqrt(1.0/d['flux_err2invsum'])
        d['flux_s2n'] = d['flux_s2n_sum']/d['nsum']
        d['T'] = d['T_sum']/d['nsum']
        d['T_err'] = sqrt(1.0/d['T_err2invsum'])
        d['T_s2n'] = d['T_s2n_sum']/d['nsum']

def get_jackknife_eps(fname):
    dirname=os.path.dirname(fname)
    bname=os.path.basename(fname)

    pdir = dirname.replace('outputs','plots')
    if not os.path.exists(pdir):
        os.makedirs(pdir)

    jname=bname.replace('.fits','-jackknife.eps')

    jname = os.path.join(pdir, jname)
    return jname

def do_sums_jackknife(conf, fobj, d, options):
    # we can't do jackknifing by chunks

    data = fobj[1][:]
    conf['eps']=get_jackknife_eps(conf['fname'])
    do_sums(conf, data, d, options)

def do_sums_bychunk(conf, fobj, d, options):
    nrows=fobj[1].get_nrows()
    nchunks = get_chunk_info(nrows)

    for i in xrange(nchunks):
        beg = i*CHUNKSIZE
        end = (i+1)*CHUNKSIZE
        print >>stderr,'    %s:%s of %s' % (beg,end,nrows)
        data = fobj[1][beg:end]

        do_sums(conf, data, d, options)

def get_averaged(conf, s2n_matched, options):

    model=conf['fit_model']

    print >>stderr,conf['fname']
    with fitsio.FITS(conf['fname']) as fobj:

        dt= get_dtype(fobj,model)

        d=numpy.zeros(1, dtype=dt)
        d['s2n_matched'] = s2n_matched

        if options.jackknife:
            do_sums_jackknife(conf, fobj, d, options)
        else:
            do_sums_bychunk(conf, fobj, d, options)

    do_avg(conf, d)

    return d

def pqr_jackknife(P, Q, R,
                  chunksize=1,
                  get_sums=False,
                  get_shears=False,
                  progress=False,
                  show=False,
                  eps=None,
                  png=None):
    """
    Get the shear covariance matrix using jackknife resampling.

    The trick is that this must be done in pairs

    chunksize is the number of *pairs* to remove for each chunk
    """

    if progress:
        import progressbar
        pg=progressbar.ProgressBar(width=70)

    ntot = P.size
    if ( (ntot % 2) != 0 ):
        raise  ValueError("expected factor of two, got %d" % ntot)
    npair = ntot/2

    # some may not get used
    nchunks = npair/chunksize

    P_sum, Q_sum, Cinv_sum = lensing.pqr.get_pqr_sums(P,Q,R)
    C = numpy.linalg.inv(Cinv_sum)
    shear = numpy.dot(C,Q_sum)

    shears = numpy.zeros( (nchunks, 2) )
    for i in xrange(nchunks):

        beg = i*chunksize*2
        end = (i+1)*chunksize*2
        
        if progress:
            frac=float(i+1)/nchunks
            pg.update(frac=frac)

        Ptmp = P[beg:end]
        Qtmp = Q[beg:end,:]
        Rtmp = R[beg:end,:,:]

        P_sum, Q_sum_tmp, Cinv_sum_tmp = \
                lensing.pqr.get_pqr_sums(Ptmp,Qtmp,Rtmp)
        
        Q_sum_tmp    = Q_sum - Q_sum_tmp
        Cinv_sum_tmp = Cinv_sum - Cinv_sum_tmp

        Ctmp = numpy.linalg.inv(Cinv_sum_tmp)
        shear_tmp = numpy.dot(C,Q_sum_tmp)

        shears[i, :] = shear_tmp

    shear_cov = numpy.zeros( (2,2) )
    fac = (nchunks-1)/float(nchunks)

    shear = shears.mean(axis=0)

    shear_cov[0,0] = fac*( ((shear[0]-shears[:,0])**2).sum() )
    shear_cov[0,1] = fac*( ((shear[0]-shears[:,0]) * (shear[1]-shears[:,1])).sum() )
    shear_cov[1,0] = shear_cov[0,1]
    shear_cov[1,1] = fac*( ((shear[1]-shears[:,1])**2).sum() )

    if show or eps or png:
        lensing.pqr._plot_shears(shears, show=show, eps=eps, png=png)

    if get_sums:
        return shear, shear_cov, Q_sum, Cinv_sum
    elif get_shears:
        return shear, shear_cov, shears
    else:
        return shear, shear_cov



def main():
    options,args = parser.parse_args(sys.argv[1:])

    if len(args) < 2:
        parser.print_help()
        sys.exit(45)


    run=args[0]
    is2n=int(args[1])

    if options.skip is None:
        skip=[]
    else:
        skip = [int(v) for v in options.skip.split(',')]

    c = nsim.files.read_config(run)
    c['simc'] = nsim.files.read_config(c['sim'])

    s2n_vals    = c['s2n_vals']

    s2n_matched = s2n_vals[is2n]
    c['fname']=nsim.files.get_output_url(run, 0, is2n)

    output = get_averaged(c, s2n_matched, options)

    out_fname=nsim.files.get_averaged_url(run, is2n=is2n)
    print >>stderr,'writing:',out_fname
    fitsio.write(out_fname, output, clobber=True)


main()
