#!/usr/bin/env python
from __future__ import print_function
import sys
import os
from pprint import pprint
import numpy
from numpy import sqrt, array, diag, ones, zeros, where, newaxis
from numpy import newaxis
import biggles

import fitsio

import ngmix
import nsim
from nsim import files

import argparse
import esutil as eu
from esutil.numpy_util import between

import reredux


fclass=argparse.ArgumentDefaultsHelpFormatter
parser=argparse.ArgumentParser(formatter_class=fclass)

parser.add_argument('runs', nargs='+',help='run to use in fit')

parser.add_argument('--select',default=None,
                    help='string for selection, refer to data[field] etc.')

parser.add_argument('--ntest',default=None,type=int,
                    help='work on a small subset for quick tests')

parser.add_argument('--nocorr',action='store_true',
                    help='do not apply correlated noise correction')

parser.add_argument('--boot-Rnoise',action='store_true')
parser.add_argument('--nboot-Rnoise',type=int,default=100)
parser.add_argument('--bootsize-Rnoise',type=int,default=1000000)

parser.add_argument('--weights',action='store_true')
parser.add_argument('--s2n-soft',type=float,default=20)

parser.add_argument('--no-Rpsf-noise',action='store_true')

parser.add_argument('--show',action='store_true',help='show plot')
parser.add_argument('--yrange', help="yrange of plot")
parser.add_argument('--xrange', help="xrange of plot")

parser.add_argument('--fit-only',action='store_true',
                    help='get the means from the written file')

default_columns=[
    'shear_index',
    'mcal_g',
    'mcal_gpsf',
    'mcal_R',
    'mcal_Rpsf',
    'mcal_dt_Rnoise',
    'mcal_dt_Rnoise_psf',
]

cache_columns=[
    'shear_index',
    'pars',
    's2n_r',
    'mcal_g',
    'mcal_gpsf',
    'mcal_R',
    'mcal_Rpsf',
    'mcal_dt_Rnoise',
    'mcal_dt_Rnoise_psf',
]

class BNamer(object):
    """
    create strings with a specified front prefix
    """
    def __init__(self, back=None):
        self.back=back
    def __call__(self, name):
        if self.back is None or self.back=='':
            return name
        else:
            return '%s_%s' % (name,self.back)


def get_subset(conf, args, fname, **kw):

    docuts=False
    types=['min_s2n','min_logF']
    for t in types:
        if kw[t] is not None:
            docuts=True

    if not docuts:
        return None

    with fitsio.FITS(fname) as fobj:
        nrows = fobj[1].get_nrows()
        logic = numpy.ones(nrows,dtype=bool)

        if kw['min_s2n'] is not None:
            print("making s2n cut:",kw['min_s2n'])

            columns=['s2n_r']
            print("reading cut fields only:",columns)
            t=fitsio.read(fname, columns=columns)

            logic = logic & (t['s2n_r'] > kw['min_s2n'])

        if kw['min_logF'] is not None:
            print("making logF cut:",kw['min_logF'])

            columns=['pars']
            print("reading cut fields only:",columns)
            t=fitsio.read(fname, columns=columns)

            logic = logic & (t['pars'][:,5] > kw['min_logF'])

    w,=numpy.where(logic)
    print("    kept: %d/%d" % (w.size,logic.size))

    return w

def get_cache_file(runs):

    rlist='-'.join(runs)
    rlist=rlist.replace('run-','')

    tdir=os.environ['TMPDIR']
    tfile= nsim.files.get_output_url(runs[0], 0, 0)
    tfile=os.path.basename(tfile)

    tfile=tfile.replace(runs[0], rlist)
    tfile=os.path.join(tdir, tfile)
    return tfile

def count_objects(flist):

    n=0
    for fname in flist:
        with fitsio.FITS(fname) as fits:
            n += fits[1].get_nrows()

    return n

def cache_in_chunks(runs, columns, cache_file):

    print("cacheing columns:")
    pprint(columns)

    chunksize=1000000

    first=True
    with fitsio.FITS(cache_file,'rw',clobber=True) as output:
        for run in runs:

            fname = nsim.files.get_output_url(run, 0, 0)
            print(fname)

            with fitsio.FITS(fname) as fits:

                hdu=fits[1]

                nrows=hdu.get_nrows()
                nchunks = nrows//chunksize

                if (nrows % chunksize) > 0:
                    nchunks += 1

                beg=0
                for i in xrange(nchunks):
                    print("    chunk %d/%d" % (i+1,nchunks))

                    end=beg+chunksize

                    data = hdu[columns][beg:end]

                    if first:
                        output.write(data)
                        first=False
                    else:
                        output[-1].append(data)

                    beg = beg + chunksize

def read_data(conf, args, **kw):

    columns = default_columns
    ccolumns = cache_columns

    if args.no_Rpsf_noise:
        columns=[c for c in columns if c != 'mcal_dt_Rnoise_psf']
        ccolumns=[c for c in ccolumns if c != 'mcal_dt_Rnoise_psf']

    cache_file=get_cache_file(args.runs)
    print("cache file:",cache_file)

    if not os.path.exists(cache_file):
        cache_in_chunks(args.runs, ccolumns, cache_file)

    print("reading cache:",cache_file)

    if len(kw) > 0:
        print("getting subset")
        rows=get_subset(conf, args, cache_file, **kw)
    elif args.ntest is not None:
        rows=numpy.arange(args.ntest)
        print("reading",rows.size,"rows")
    else:
        print("reading all")
        rows=None

    #rows=numpy.arange(1000000)
    #data=fitsio.read(cache_file,columns=columns,rows=rows)
    data=fitsio.read(cache_file,rows=rows)

    return data



SIGMA2_MIN_CONSTANT_GROUND = 4.     # 2**2
NORMALIZATION_CONSTANT_SPACE = 1.232
NORMALIZATION_CONSTANT_GROUND = NORMALIZATION_CONSTANT_SPACE

CFID = 2.e-4
MFID = 2.e-3

def fitpoly(noise0, noises, Rdiff, Rdiff_err):
    fitter=Fitter(noise0, noises, Rdiff, Rdiff_err)
    fitter.dofit()
    #print(fitter)
    if False:
        fitter.plot(show=True)
        if raw_input('hit a key: ')=='q':
            stop

    res=fitter.get_result()
    return res

def fitpolyold(n0, noises, R0, R0err, Rnoise, Rnoise_err):
    ntot = noises.size + 1

    noise_tot = zeros(ntot)
    noise_tot[0] = n0
    noise_tot[1:] = noises

    Rtot = zeros(ntot)
    Rtot_err = zeros(ntot)
    Rtot[0] = R0
    Rtot[1:] = Rnoise
    Rtot_err[0] = R0err
    Rtot_err[1:] = Rnoise_err
    
    if True:
        biggles.plot(noise_tot, Rtot)
        stop

    fitter=Fitter(noise_tot, Rtot, Rtot_err)
    fitter.dofit()
    print(fitter)

    res=fitter.get_result()
    R = res['pars'][0]
    Rerr = res['perr'][0]

    return R, Rerr


class Fitter(object):
    def __init__(self, x0, x, y, yerr):

        self.x0=x0
        self.x=x

        self.xdiff=x-x0
        self.x2diff=x**2 - x0**2
        self.y=y
        self.yerr=yerr

        self.npars=2

        self._set_guess()

    def get_result(self):
        return self._result

    def dofit(self):
        from scipy.optimize import leastsq
        res=leastsq(self._errfunc, self.guess, full_output=1)

        pars, pcov0, infodict, errmsg, ier = res
        if ier == 0:
            # wrong args, this is a bug
            raise ValueError(errmsg)

        numiter = infodict['nfev']
        pcov=None
        perr=None

        if pcov0 is not None:
            pcov = self._scale_leastsq_cov(pars, pcov0)

            d=numpy.diag(pcov)
            w,=numpy.where(d < 0)

            if w.size == 0:
                # only do if non negative
                perr = numpy.sqrt(d)

        self._result={'pars':pars, 'pcov':pcov, 'perr':perr,'errmsg':errmsg}


    def _set_guess(self):
        """
        [a, b]
        a (x^2 - x0^2) + b (x-x0)
        """
        self.guess = array([-0.1, 0.1])

    def eval_pars(self, pars, x=None):
        """
        [a, b]
        a (x^2 - x0^2) + b (x-x0)
        """

        if x is not None:
            xdiff=x-self.x0
            x2diff=x**2 - self.x0**2
        else:
            xdiff=self.xdiff
            x2diff=self.x2diff

        return pars[0]*x2diff + pars[1]*xdiff

    def _errfunc(self, pars):
        model = self.eval_pars(pars)
        diff = (model-self.y)/self.yerr
        return diff.ravel()

    def _scale_leastsq_cov(self, pars, pcov):
        """
        Scale the covariance matrix returned from leastsq; this will
        recover the covariance of the parameters in the right units.
        """

        # is total size right here?
        dof = (self.y.size-len(pars))
        s_sq = (self._errfunc(pars)**2).sum()/dof
        return pcov * s_sq 

    def plot(self, show=False):
        import biggles
        pars=self._result['pars']
        perr=self._result['perr']

        x=numpy.linspace(self.x0, self.x.max(),100)
        x2diff=x**2 - self.x0**2
        yfit = self.eval_pars(pars, x=x)

        plt=biggles.FramedPlot()

        pts=biggles.Points(self.x2diff, self.y)
        err=biggles.SymmetricErrorBarsY(self.x2diff, self.y, self.yerr)

        c=biggles.Curve(x2diff, yfit, type='solid', color='blue')

        plt.add(c, pts, err)

        alab=r'$A = %.3g \pm %.3g' % (pars[0], perr[0])
        blab=r'$B = %.3g \pm %.3g' % (pars[1], perr[1])
        alabel=biggles.PlotLabel(0.9, 0.9, alab, halign='right')
        blabel=biggles.PlotLabel(0.9, 0.85, blab, halign='right')

        plt.add(alabel, blabel)

        if show:
            plt.show()
        return plt



    def __repr__(self):
        if hasattr(self,'_result'):
            pars=self._result['pars']
            perr=self._result['perr']

            rep = """
    a (x^2-x0^2) + b (x-x0)
    a: %g +/- %g
    b: %g +/- %g\n""" % (pars[0],perr[0],pars[1],perr[1])

        return rep



class FitterOld(object):
    def __init__(self, x, y, yerr):

        self.x=x

        self.xsq=x**2
        self.diffx = x - x[0]

        self.y=y
        self.yerr=yerr

        self.npars=2

        self._set_guess()

    def get_result(self):
        return self._result

    def dofit(self):
        from scipy.optimize import leastsq
        res=leastsq(self._errfunc, self.guess, full_output=1)

        pars, pcov0, infodict, errmsg, ier = res
        if ier == 0:
            # wrong args, this is a bug
            raise ValueError(errmsg)

        numiter = infodict['nfev']
        pcov=None
        perr=None

        if pcov0 is not None:
            pcov = self._scale_leastsq_cov(pars, pcov0)

            d=numpy.diag(pcov)
            w,=numpy.where(d < 0)

            if w.size == 0:
                # only do if non negative
                perr = numpy.sqrt(d)

        self._result={'pars':pars, 'pcov':pcov, 'perr':perr}


    def _set_guess(self):
        """
        [R, a, b]
        R +  a (x-x0) + b x^2
        """
        self.guess = array([0.5, 0.1, -0.1])

    def eval_pars(self, pars):
        """
        [R, a, b]
        R +  a (x-x0) + b x^2
        """

        return pars[0] + pars[1]*self.diffx + pars[2]*self.xsq

    def _errfunc(self, pars):
        model = self.eval_pars(pars)
        diff = (model-self.y)/self.yerr
        return diff.ravel()

    def _scale_leastsq_cov(self, pars, pcov):
        """
        Scale the covariance matrix returned from leastsq; this will
        recover the covariance of the parameters in the right units.
        """

        # is total size right here?
        dof = (self.x.size-len(pars))
        s_sq = (self._errfunc(pars)**2).sum()/dof
        return pcov * s_sq 

    def __call__(self, x):
        """
        pars order same as for numpy.poly1d
        """
        return self.eval_pars(self._result['pars'])

    def __repr__(self):
        if hasattr(self,'_result'):
            pars=self._result['pars']
            perr=self._result['perr']

            rep = """
    R + a dx + b x^2
    R: %g +/- %g
    a: %g +/- %g
    b: %g +/- %g\n""" % (pars[0],perr[0],pars[1],perr[1],pars[2],perr[2])

        return rep



# quick line fit pulled from great3-public code
def _calculateSvalues(xarr, yarr, sigma2=1.):
    """Calculates the intermediate S values required for basic linear regression.

    See, e.g., Numerical Recipes (Press et al 1992) Section 15.2.
    """
    if len(xarr) != len(yarr):
        raise ValueError("Input xarr and yarr differ in length!")
    if len(xarr) <= 1:
        raise ValueError("Input arrays must have 2 or more values elements.")

    S = len(xarr) / sigma2
    Sx = numpy.sum(xarr / sigma2)
    Sy = numpy.sum(yarr / sigma2)
    Sxx = numpy.sum(xarr * xarr / sigma2)
    Sxy = numpy.sum(xarr * yarr / sigma2)
    return (S, Sx, Sy, Sxx, Sxy)

def fitline(xarr, yarr):
    """Fit a line y = a + b * x to input x and y arrays by least squares.

    Returns the tuple (a, b, Var(a), Cov(a, b), Var(b)), after performing an internal estimate of
    measurement errors from the best-fitting model residuals.

    See Numerical Recipes (Press et al 1992; Section 15.2) for a clear description of the details
    of this simple regression.
    """
    # Get the S values (use default sigma2, best fit a and b still valid for stationary data)
    S, Sx, Sy, Sxx, Sxy = _calculateSvalues(xarr, yarr)
    # Get the best fit a and b
    Del = S * Sxx - Sx * Sx
    a = (Sxx * Sy - Sx * Sxy) / Del
    b = (S * Sxy - Sx * Sy) / Del
    # Use these to estimate the sigma^2 by residuals from the best-fitting model
    ymodel = a + b * xarr
    sigma2 = numpy.mean((yarr - ymodel)**2)
    # And use this to get model parameter error estimates
    var_a  = sigma2 * Sxx / Del
    cov_ab = - sigma2 * Sx / Del
    var_b  = sigma2 * S / Del

    a_err = numpy.sqrt(var_a)
    b_err = numpy.sqrt(var_b)

    return {'offset':a,
            'offset_err':a_err,
            'slope':b,
            'slope_err':b_err,
            'cov':cov_ab}
    #return a, a_err, b, b_err, cov_ab

def fitline_zero_offset(x, y):

    # Our model is y = a * x, so things are quite simple, in this case...
    # x needs to be a column vector instead of a 1D vector for this, however.
    x = x[:,numpy.newaxis]
    a, _, _, _ = numpy.linalg.lstsq(x, y)

    return {'offset':0.0,
            'offset_err':0.0,
            'slope':a[0],
            'slope_err':0.0}
    
def calc_q(fits):

    m1=fits['m'][0,0]
    m2=fits['m'][0,1]
    c1=fits['c'][0,0]
    c2=fits['c'][0,1]

    sigma2_min = SIGMA2_MIN_CONSTANT_GROUND 
    norm = NORMALIZATION_CONSTANT_GROUND 

    num = 2000.0 * norm
    denom = numpy.sqrt(  (c1 / CFID)**2 
                       + (c2 / CFID)**2
                       + (m1 / MFID)**2
                       + (m2 / MFID)**2
                       + sigma2_min)

    Q = num/denom
    
    print("  Q: %g" % Q)

    return Q

def doplot(args, data, fits):
    import biggles

    #Q=calc_q(fits)

    if args.yrange is not None:
        yrange=[float(r) for r in args.yrange.split(',')]
    else:
        yrange=[-0.01,0.01]

    xrng=args.xrange
    if xrng is not None:
        xrng=[float(r) for r in args.xrange.split(',')]

    tab=biggles.Table(1,2)
    tab.aspect_ratio=0.5

    diff = data['shear'] - data['shear_true']

    plts=[]
    for i in [0,1]:

        x = data['shear_true'][:,i]
        plt =biggles.plot(
            x,
            diff[:,i],
            xlabel='shear%d true' % (i+1,),
            ylabel='shear%d diff' % (i+1,),
            yrange=yrange,
            xrange=xrng,
            visible=False,
        )
        yfit=fits['m'][0,i]*x + fits['c'][0,i]

        z=biggles.Curve(x, x*0, color='black')
        c=biggles.Curve(x, yfit, color='red')
        plt.add(z,c)

        mstr='m%d: %.2g +/- %.2g' % (i+1,fits['m'][0,i],fits['merr'][0,i])
        cstr='c%d: %.2g +/- %.2g' % (i+1,fits['c'][0,i],fits['cerr'][0,i])
        mlab=biggles.PlotLabel(0.1,0.9,
                               mstr,
                               halign='left')
        clab=biggles.PlotLabel(0.1,0.85,
                               cstr,
                               halign='left')
        plt.add(mlab,clab)
        if False and i==0:
            Qstr='Q: %d' % (int(Q),)
            Qlab=biggles.PlotLabel(0.1,0.8,
                                   Qstr,
                                   halign='left')
            plt.add(Qlab)


        tab[0,i] = plt

    #fname=reredux.files.get_fit_file(args.run,
    #                                 extra='fit-m-c',
    #                                 ext='eps')
    #eu.ostools.makedirs_fromfile(fname)
    #print("writing:",fname)
    #tab.write_eps(fname)

    if args.show:
        tab.show(width=1000, height=1000)

def get_mean_struct(n):
    dt=[('shear','f8',2),
        ('shear_true','f8',2),
        ('shear_err','f8',2)]

    means = numpy.zeros(n, dtype=dt)
    return means

def get_boot_struct(nboot):
    dt=[('m','f8',2),
        ('c','f8',2)]

    bs = numpy.zeros(nboot, dtype=dt)
    return bs

def read_means(args):
    return reredux.files.read_fit_file(args.run,
                                       extra='shear-means')
def write_means(args, means):
    fname=reredux.files.get_fit_file(args.run,
                                     extra='shear-means')
    eu.ostools.makedirs_fromfile(fname)

    print("writing:",fname)
    fitsio.write(fname, means, clobber=True)


def print_shear(ind, num, shear, shear_err):
    mess="  %d: %d  %g +/- %g  %g +/- %g"
    tup=(ind, num, shear[0],shear_err[0], shear[1],shear_err[1])
    print(mess % tup)


def add_fake_shear(conf, args, data, Rnoise, Rnoise_sel, index, shear):
    """
    add shear using the individual R values
    """
    g = data['mcal_g']
    R = data['mcal_R']

    R11 = R[:,0,0].copy()
    R22 = R[:,1,1].copy()
    R11_sel = R[index,0,0].copy()
    R22_sel = R[index,1,1].copy()

    R11 -= Rnoise[0,0]
    R22 -= Rnoise[1,1]
    R11_sel -= Rnoise_sel[0,0]
    R22_sel -= Rnoise_sel[1,1]

    g1 = g[:,0] - g[:,0].mean()
    g2 = g[:,1] - g[:,1].mean()

    print("making sheared")
    sg1,junk = ngmix.shape.shear_reduced(g1,
                                         g2,
                                         shear*R11,
                                         0.0)
    junk,sg2 = ngmix.shape.shear_reduced(g1,
                                         g2,
                                         0.0,
                                         shear*R22)

    sg1_sel,junk = ngmix.shape.shear_reduced(g1[index],
                                             g2[index],
                                             shear*R11_sel,
                                             0.0)
    junk,sg2_sel = ngmix.shape.shear_reduced(g1[index],
                                             g2[index],
                                             0.0,
                                             shear*R22_sel)

    return sg1, sg2, sg1_sel, sg2_sel

def do_sums1(nshear, data, args, sums=None, select=None):

    n_detrend = data['mcal_dt_Rnoise'].shape[1]

    h,rev = eu.stat.histogram(data['shear_index'],
                              min=0,
                              max=nshear-1,
                              rev=True)
    nind = h.size
    assert nshear==nind

    if sums is None:
        dt=[
            ('n','i8'),
            ('g','f8',2),
            ('gpsf','f8',2),
            ('R','f8',(2,2)),
            ('Rpsf','f8',2),
            ('Rdt','f8',(n_detrend,2,2)),
            ('Rdt_psf','f8',(n_detrend,2)),
        ]

        sums=numpy.zeros(nshear, dtype=dt)

    for i in xrange(nshear):
        if rev[i] != rev[i+1]:
            w=rev[ rev[i]:rev[i+1] ]

            t=data[w]

            if select is not None:
                logic=eval(select)
                w,=numpy.where(logic)
                print("        keeping %d/%d from cuts" % (w.size,t.size))
                t=t[w]

            sums['n'][i] += w.size
            sums['g'][i] += t['mcal_g'].sum(axis=0)
            sums['gpsf'][i] += t['mcal_gpsf'].sum(axis=0)

            sums['R'][i] += t['mcal_R'].sum(axis=0)
            sums['Rpsf'][i] += t['mcal_Rpsf'].sum(axis=0)

            if not args.nocorr:

                sums['Rdt'][i] += t['mcal_dt_Rnoise'].sum(axis=0)

                if not args.no_Rpsf_noise:
                    sums['Rdt_psf'][i] += t['mcal_dt_Rnoise_psf'].sum(axis=0)

    return sums

def do_sums(conf, args, fake_dict=None):

    sconf=conf['simc']
    shears = sconf['shear']['shears']
    nshear=len(shears)

    chunksize=1000000
    sums=None
    sums_select=None
    ntot=0
    for run in args.runs:
        if args.ntest is not None and ntot > args.ntest:
            break

        fname = nsim.files.get_output_url(run, 0, 0)
        print(fname)
        with fitsio.FITS(fname) as fits:

            hdu=fits[1]

            nrows=hdu.get_nrows()
            nchunks = nrows//chunksize

            if (nrows % chunksize) > 0:
                nchunks += 1

            beg=0
            for i in xrange(nchunks):
                print("    chunk %d/%d" % (i+1,nchunks))

                end=beg+chunksize

                data = hdu[beg:end]
                ntot += data.size

                sums=do_sums1(nshear, data, args, sums=sums)
                if args.select is not None:
                    sums_select=do_sums1(nshear, data, args, sums=sums_select,
                                         select=args.select)

                beg = beg + chunksize

                if args.ntest is not None and ntot > args.ntest:
                    break
    return sums, sums_select

def read_and_average(conf, args):

    sconf=conf['simc']
    shears = sconf['shear']['shears']
    nshear=len(shears)

    sums, sums_select = do_sums(conf, args)

    # convert to averages
    ntot=sums['n'].sum()
    R = sums['R'].sum(axis=0)/ntot
    Rpsf = sums['Rpsf'].sum(axis=0)/ntot

    if not args.nocorr:
        Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                get_Rnoise_line(conf, args, None, sums=sums)

        R -= Rnoise
        Rpsf -= Rnoise_psf

        if sums_select is not None:
            ntot_sel =sums_select['n'].sum()
            R_sel = sums_select['R'].sum(axis=0)/ntot_sel
            Rpsf_sel = sums_select['Rpsf'].sum(axis=0)/ntot_sel

            Rnoise_sel, terr, Rnoise_psf_sel, terr = \
                    get_Rnoise_line(conf, args, None, sums=sums_select)

            R_sel -= Rnoise_sel
            Rpsf_sel -= Rnoise_psf_sel

    if sums_select is not None:
        # using the mean R values
        sel = get_selection_effect(conf, args, R_noise, Rnoise_sel)
        sums_no_select=sums
        sums=sums_select

    g = sums['g']
    gpsf = sums['gpsf']

    ninv = 1.0/sums['n']
    g[:,0]    *= ninv
    g[:,1]    *= ninv
    gpsf[:,0] *= ninv
    gpsf[:,1] *= ninv

    Rinv = numpy.linalg.inv(R)

    means=get_mean_struct(nshear)

    for i in xrange(nshear):

        shear_true = shears[i]

        psf_corr  = Rpsf*gpsf[i]

        gmean     = g[i]
        shear     = numpy.dot(Rinv, gmean-psf_corr)

        means['shear'][i] = shear
        means['shear_err'][i] = 1.0
        means['shear_true'][i] = shear_true

    return means

class Summer(dict):
    def __init__(self, conf, args):
        self.update(conf)
        self.args=args

        self.chunksize=1000000

        sconf=self['simc']

        self['nshear']=len(self['simc']['shear']['shears'])
        print("nshear:",self['nshear'])

        '''
        shears_array=array(self['simc']['shear']['shears'])

        # fake shear for selection effects
        sh = sqrt(shears_array[:,0]**2 + shears_array[:,1]**2)
        # in each component
        self['fake_shear']=sh.mean()/sqrt(2)

        #self['fake_shear']=0.045
        '''
        self['fake_shear']=0.01

        print("fake shear:",self['fake_shear'])

    def go(self):
        sums, sums_select = self.do_sums()

        args=self.args

        for i,tsums in enumerate([sums,sums_select]):
            if tsums is None:
                continue

            if i == 0:
                n=BNamer()
            else:
                n=BNamer('sel')

            # averated over all shear fields
            ntot=tsums['n'].sum()
            self[n('R')] = tsums['R'].sum(axis=0)/ntot
            self[n('Rpsf')] = tsums['Rpsf'].sum(axis=0)/ntot

            if not args.nocorr:
                Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                        get_Rnoise_line(self, args, None, sums=tsums)

                self[n('R')] -= Rnoise
                self[n('Rpsf')] -= Rnoise_psf
                self[n('Rnoise')] = Rnoise
                self[n('Rnoise_psf')] = Rnoise_psf

            self[n('Rinv')] = numpy.linalg.inv( self[n('R')] )

        if sums_select is not None:
            # using the mean R values
            self.sel = self.get_selection_effect()
            #self.sel=array([1.0,1.0])
            sums_no_select=sums
            sums=sums_select

            n=BNamer('sel')
        else:
            self.sel=array([1.0,1.0])
            n=BNamer()

        print("sel:",self.sel)


        g = sums['g'].copy()
        gpsf = sums['gpsf'].copy()

        ninv = 1.0/sums['n']
        g[:,0]    *= ninv
        g[:,1]    *= ninv
        gpsf[:,0] *= ninv
        gpsf[:,1] *= ninv

        # using mean responses
        Rpsf = self[n('Rpsf')]
        Rinv = self[n('Rinv')]

        shears=self['simc']['shear']['shears']
        means=get_mean_struct(self['nshear'])
        for i in xrange(self['nshear']):

            shear_true = shears[i]

            psf_corr  = Rpsf*gpsf[i]

            gmean     = g[i]
            shear     = numpy.dot(Rinv, gmean-psf_corr)

            means['shear'][i] = shear
            means['shear_err'][i] = 1.0
            means['shear_true'][i] = shear_true

        means['shear'][:,0] *= self.sel[0]
        means['shear'][:,1] *= self.sel[1]

        self.means=means


    def get_selection_effect(self):

        sums, sums_select = self.do_sums(add_fake_shear=True)

        sheard={}

        for i,tsums in enumerate([sums, sums_select]):
            if i==0:
                n=BNamer()
            else:
                n=BNamer('sel')

            # we added shear to all fields, so we sum over shear_index
            ntot = tsums['n'].sum()
            g    = tsums['g'].sum(axis=0)/ntot
            gpsf = tsums['gpsf'].sum(axis=0)/ntot

            psf_corr  = self[n('Rpsf')]*gpsf[i]

            sheard[n('shear')] = numpy.dot(self[n('Rinv')], g-psf_corr)

        sel = sheard['shear']/sheard['shear_sel']

        return sel

    def do_sums(self, add_fake_shear=False):
        chunksize=self.chunksize
        args=self.args

        sconf=self['simc']

        sums=None
        sums_select=None
        ntot=0
        for run in args.runs:
            if args.ntest is not None and ntot > args.ntest:
                break

            fname = nsim.files.get_output_url(run, 0, 0)
            print(fname)
            with fitsio.FITS(fname) as fits:

                hdu=fits[1]

                nrows=hdu.get_nrows()
                nchunks = nrows//chunksize

                if (nrows % chunksize) > 0:
                    nchunks += 1

                beg=0
                for i in xrange(nchunks):
                    print("    chunk %d/%d" % (i+1,nchunks))

                    end=beg+chunksize

                    data = hdu[beg:end]
                    ntot += data.size

                    if add_fake_shear:
                        #tmp_data=self.add_fake_shear_noR(data)
                        tmp_data=self.add_fake_shear(data, self['Rnoise'])
                        #tmp_data=self.add_fake_shear(data, self['Rnoise'], R=self['R'])
                    else:
                        tmp_data=data

                    sums=self.do_sums1(tmp_data, sums=sums)

                    if args.select is not None:

                        logic=eval(args.select)
                        w,=numpy.where(logic)
                        print("        keeping %d/%d from cuts" % (w.size,data.size))
                        sdata=data[w]

                        # Rnoise is different, so we add shear separately for
                        # the selected data

                        if add_fake_shear:
                            #tmp_sdata=self.add_fake_shear_noR(sdata)
                            tmp_sdata=self.add_fake_shear(sdata, self['Rnoise_sel'])
                            #tmp_sdata=self.add_fake_shear(sdata, self['Rnoise_sel'], R=self['R_sel'])
                        else:
                            tmp_sdata = sdata

                        sums_select=self.do_sums1(tmp_sdata, sums=sums_select)

                    beg = beg + chunksize

                    if args.ntest is not None and ntot > args.ntest:
                        break

        if add_fake_shear:
            # the shear is being simulated
            # we don't add the Rpsf when adding fake shear; should we?
            for n in ['Rpsf','Rdt_psf']:
                sums[n] = 0.0
                sums_select[n] = 0.0

        return sums, sums_select

    def do_sums1(self, data, sums=None):
        """
        just a binner and summer, no logic here
        """
        nshear=self['nshear']
        args=self.args

        n_detrend = data['mcal_dt_Rnoise'].shape[1]

        h,rev = eu.stat.histogram(data['shear_index'],
                                  min=0,
                                  max=nshear-1,
                                  rev=True)
        nind = h.size
        assert nshear==nind

        if sums is None:
            dt=[
                ('n','i8'),
                ('g','f8',2),
                ('gpsf','f8',2),
                ('R','f8',(2,2)),
                ('Rpsf','f8',2),
                ('Rdt','f8',(n_detrend,2,2)),
                ('Rdt_psf','f8',(n_detrend,2)),
            ]

            sums=numpy.zeros(nshear, dtype=dt)

        for i in xrange(nshear):
            if rev[i] != rev[i+1]:
                w=rev[ rev[i]:rev[i+1] ]

                t=data[w]


                sums['n'][i] += w.size
                sums['g'][i] += t['mcal_g'].sum(axis=0)
                sums['gpsf'][i] += t['mcal_gpsf'].sum(axis=0)

                sums['R'][i] += t['mcal_R'].sum(axis=0)
                sums['Rpsf'][i] += t['mcal_Rpsf'].sum(axis=0)

                if not args.nocorr:

                    sums['Rdt'][i] += t['mcal_dt_Rnoise'].sum(axis=0)

                    if not args.no_Rpsf_noise:
                        sums['Rdt_psf'][i] += t['mcal_dt_Rnoise_psf'].sum(axis=0)

        return sums

    def add_fake_shear(self, data_in, Rnoise, R=None, reflect=False):
        """
        add shear using the individual R values
        """

        data=data_in.copy()

        # applied separately in each component
        shear=self['fake_shear']

        g = data['mcal_g']

        n=g.shape[0]

        if R is None:
            print("        using individual R values")
            R = data['mcal_R']
            R11 = R[:,0,0].copy()
            R22 = R[:,1,1].copy()

            R11 -= Rnoise[0,0]
            R22 -= Rnoise[1,1]

            if reflect:
                print("        R new")
                tR11 = R11
                tR22 = R22
                R11 = zeros(n*2)
                R22 = zeros(n*2)
                R11[0:n] = tR11
                R11[n:]  = tR11
                R22[0:n] = tR22
                R22[n:]  = tR22
        else:
            print("        using mean R values")
            R11 = R[0,0]
            R22 = R[1,1]

        # currently subtracting mean to remove psf anisotropy, and
        # we set Rpsf=0
        if reflect:
            print("        g new")
            g1sub = g[:,0] - g[:,0].mean()
            g2sub = g[:,1] - g[:,1].mean()

            g1 = zeros(n*2)
            g2 = zeros(n*2)
            g1[0:n] = g1sub
            g1[n:] = -g1sub
            g2[0:n] = g2sub
            g2[n:] = -g2sub

        elif False:
            print("    subtracting mean")
            g1 = g[:,0] - g[:,0].mean()
            g2 = g[:,1] - g[:,1].mean()
        elif False:
            print("    not subtracting mean")
            g1 = g[:,0]
            g2 = g[:,1]

        print("        making sheared")
        shear1 = shear*R11
        print("        shear1 min max:",shear1.min(),shear1.max())
        sg1,junk = ngmix.shape.shear_reduced(g1,
                                             g2,
                                             shear1,
                                             0.0)
        shear2=shear*R22
        print("        shear2 min max:",shear2.min(),shear2.max())
        junk,sg2 = ngmix.shape.shear_reduced(g1,
                                             g2,
                                             0.0,
                                             shear2)

        if reflect:
            tdata=data
            data=zeros(tdata.size*2, dtype=tdata.dtype)
            data[0:n] = tdata
            data[n:] = tdata

        data['mcal_g'][:,0] = sg1
        data['mcal_g'][:,1] = sg2

        return data

    def add_fake_shear_noR(self, data_in):
        """
        add shear without response
        """

        data=data_in.copy()

        shear=self['fake_shear']

        g = data['mcal_g']

        g1 = g[:,0] - g[:,0].mean()
        g2 = g[:,1] - g[:,1].mean()

        print("        making sheared")
        sg1,junk = ngmix.shape.shear_reduced(g1,
                                             g2,
                                             shear,
                                             0.0)
        junk,sg2 = ngmix.shape.shear_reduced(g1,
                                             g2,
                                             0.0,
                                             shear)

        data['mcal_g'][:,0] = sg1
        data['mcal_g'][:,1] = sg2

        return data


def get_averages(conf, args, data, show_progress=True):

    if args.weights:
        return get_averages_weighted(conf, args, data,
                                     show_progress=show_progress)

    sconf=conf['simc']
    shears = sconf['shear']['shears']

    print("histogramming shear index")
    h,rev = eu.stat.histogram(data['shear_index'], rev=True)
    nind = h.size

    print("Getting overall means")
    g=data['mcal_g']
    gpsf=data['mcal_gpsf']

    R=data['mcal_R']
    Rpsf=data['mcal_Rpsf']

    Rmean = R.mean(axis=0)
    Rerr = R.std(axis=0)/sqrt(R.shape[0])

    Rpsf_mean = Rpsf.mean(axis=0)
    Rpsf_err = Rpsf.std(axis=0)/sqrt(R.shape[0])

    if not args.nocorr:
        print("calculating detrend correlated noise corrections")
        Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                get_Rnoise_line(conf, args, data)

        Rmean -= Rnoise
        Rpsf_mean -= Rnoise_psf

        Rerr = sqrt(Rerr**2 + Rnoise_err**2)
        Rpsf_err = sqrt(Rpsf_err**2 + Rnoise_psf_err**2)
    else:
        print("skipping correlated noise correction")

    Rinv = numpy.linalg.inv(Rmean)


    print_Rs(Rmean, Rerr, Rpsf_mean, Rpsf_err)

    means=get_mean_struct(nind)

    #psf_corr  = Rpsf_mean*gpsf.mean(axis=0)

    print("getting shear field means")
    for i in xrange(nind):
        if show_progress:
            print("shear index:",i)

        w=rev[ rev[i]:rev[i+1] ]

        shear_true = shears[i]

        psf_corr  = Rpsf_mean*gpsf[w].mean(axis=0)

        gmean     = g[w].mean(axis=0)
        shear     = numpy.dot(Rinv, gmean-psf_corr)
        shear_err = g[w].std(axis=0)/numpy.sqrt(w.size)
        shear_err = numpy.dot(Rinv, shear_err)

        means['shear'][i] = shear
        means['shear_err'][i] = shear_err
        means['shear_true'][i] = shear_true

    return means

def get_averages_weighted(conf, args, data, show_progress=True):

    print("using weights")
    weights=get_s2n_weights(data['s2n_r'], args)
    wsum=weights.sum()
    #wna1=weights[:,newaxis]
    #wna2=weights[:,newaxis,newaxis]

    sconf=conf['simc']
    shears = sconf['shear']['shears']

    h,rev = eu.stat.histogram(data['shear_index'], rev=True)
    nind = h.size

    g=data['mcal_g']
    gpsf=data['mcal_gpsf']

    R=data['mcal_R']
    Rpsf=data['mcal_Rpsf']

    print("getting Rnoise")
    Rnoise, Rnoise_psf = get_Rnoise_line(conf, args, data, weights=weights)
    #Rnoise = get_Rnoise_line(conf, args, data, weights=weights)

    print("calculating Rmean")
    Rmean = numpy.zeros( (2,2) )
    Rpsf_mean = numpy.zeros(2)
    for i in xrange(2):
        Rpsf_mean[i] = (Rpsf[:,i]*weights).sum()/wsum
        for j in xrange(2):
            Rmean[i,j] = (R[:,i,j]*weights).sum()/wsum

    Rmean = Rmean - Rnoise
    Rpsf_mean = Rpsf_mean - Rnoise_psf

    Rinv = numpy.linalg.inv(Rmean)

    means=get_mean_struct(nind)

    print("getting shears for each shear_index")
    gmean=numpy.zeros(2)
    psf_corr=numpy.zeros(2)
    for i in xrange(nind):
        if show_progress:
            print("shear index:",i)

        w=rev[ rev[i]:rev[i+1] ]

        shear_true = shears[i]

        twsum = weights[w].sum()
        for j in xrange(2):
            psf_corr[j]  = Rpsf_mean[j]*(gpsf[w,j]*weights[w]).sum()/twsum
            gmean[j]     = (g[w,j]*weights[w]).sum()/twsum

        shear = numpy.dot(Rinv, gmean-psf_corr)

        # wrong, but won't get used anyway
        shear_err = g[w].std(axis=0)/numpy.sqrt(w.size)
        shear_err = numpy.dot(Rinv, shear_err)

        means['shear'][i] = shear
        means['shear_err'][i] = shear_err
        means['shear_true'][i] = shear_true

    return means

def get_averages_boot_Rnoise(conf, args, data):

    sconf=conf['simc']
    shears = sconf['shear']['shears']

    g=data['mcal_g']
    gpsf=data['mcal_gpsf']

    R=data['mcal_R']
    Rpsf=data['mcal_Rpsf']

    Rmean0 = R.mean(axis=0)
    Rerr0 = R.std(axis=0)/sqrt(R.shape[0])

    Rpsf_mean0 = Rpsf.mean(axis=0)
    Rpsf_err0 = Rpsf.std(axis=0)/sqrt(R.shape[0])

    bs=get_boot_struct(args.nboot_Rnoise)


    h,rev = eu.stat.histogram(data['shear_index'], rev=True)
    nind = h.size

    g_means = []
    g_errs = []
    gpsf_means = []
    for i in xrange(nind):
        w=rev[ rev[i]:rev[i+1] ]

        gmean     = g[w].mean(axis=0)
        g_err = g[w].std(axis=0)/numpy.sqrt(w.size)
        gpsf_mean = gpsf[w].mean(axis=0)

        g_means.append(gmean)
        g_errs.append(g_err)
        gpsf_means.append(gpsf_mean)



    means=get_mean_struct(nind)
    for iboot in xrange(args.nboot_Rnoise):

        print("%d/%d" % (iboot+1,args.nboot_Rnoise))

        subset=numpy.random.randint(
            0,
            data.size,
            args.bootsize_Rnoise
        )

        Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                get_Rnoise_line(conf, args, data[subset])

        Rmean = Rmean0 - Rnoise
        Rpsf_mean = Rpsf_mean0 - Rnoise_psf
        Rinv = numpy.linalg.inv(Rmean)

        Rerr = sqrt(Rerr0**2 + Rnoise_err**2)
        Rpsf_err = sqrt(Rpsf_err0**2 + Rnoise_psf_err**2)

        print_Rs(Rmean, Rerr, Rpsf_mean, Rpsf_err)

        for i in xrange(nind):

            shear_true = shears[i]

            g_mean = g_means[i]
            g_err = g_errs[i]
            gpsf_mean = gpsf_means[i]

            psf_corr  = gpsf_mean*Rpsf_mean

            shear     = numpy.dot(Rinv, g_mean-psf_corr)
            shear_err = g_err
            shear_err = numpy.dot(Rinv, shear_err)

            means['shear'][i] = shear
            means['shear_err'][i] = shear_err
            means['shear_true'][i] = shear_true

        fits=reredux.averaging.fit_m_c(means)
        bs['m'][iboot] = fits['m'][0,:]
        bs['c'][iboot] = fits['c'][0,:]

    mres = eu.stat.get_stats(bs['m'])
    cres = eu.stat.get_stats(bs['c'])

    print('-'*70)
    for i in xrange(2):
        print_m_c(i+1,
                  mres['mean'][i],
                  mres['err'][i],
                  cres['mean'][i],
                  cres['err'][i])



def print_m_c(sindex, m, merr, c, cerr, r=None):

    fmt = '  m{i}: %.3e +/- %.3e c{i}: %.3e +/- %.3e'.format(i=sindex)
    if r is not None:
        fmt += '  r{i}: %.3g'.format(i=sindex)
        print(fmt % (m, merr, c, cerr,r))
    else:
        print(fmt % (m, merr, c, cerr))

def fit_m_c(data, doprint=True, onem=False):
    strue = data['shear_true']
    sdiff = data['shear'] - data['shear_true']
    serr  = data['shear_err']

    if onem:
        import reredux
        fits=numpy.zeros(1, dtype=[('m','f8'),
                                   ('merr','f8'),
                                   ('c1','f8'),
                                   ('c1err','f8'),
                                   ('c2','f8'),
                                   ('c2err','f8')])


        fitter=reredux.averaging.MCFitter(strue, sdiff, serr)
        fitter.dofit()
        res=fitter.get_result()

        pars=res['pars']
        perr=res['perr']
        fits['m'] = pars[0]
        fits['c1'] = pars[1]
        fits['c2'] = pars[2]
        fits['merr'] = perr[0]
        fits['c1err'] = perr[1]
        fits['c2err'] = perr[2]

        fmt = '  m: %.3e +/- %.3e c1: %.3e +/- %.3e c2: %.3e +/- %.3e'
        print(fmt % (pars[0],perr[0],
                     pars[1],perr[1],
                     pars[2],perr[2]))
        return fits

    fits=numpy.zeros(1, dtype=[('m','f8',2),
                               ('merr','f8',2),
                               ('c','f8',2),
                               ('cerr','f8',2),
                               ('r','f8',2)])
    for i in [0,1]:
        res = fitline(strue[:,i], sdiff[:,i])
        r = res['cov']/sqrt(res['slope_err']**2 * res['offset_err']**2)
        fits['m'][0,i] = res['slope']
        fits['merr'][0,i] = res['slope_err']
        fits['c'][0,i] = res['offset']
        fits['cerr'][0,i] = res['offset_err']
        fits['r'][0,i] = r

        if doprint:
            print_m_c(i+1, res['slope'],res['slope_err'],
                      res['offset'],res['offset_err'], r=r)

    return fits



def get_s2n_weights(s2n, args):
    #return numpy.ones(s2n.size)
    print("s2n soft:",args.s2n_soft)
    wts = 1.0/(1.0 + (args.s2n_soft/s2n)**2 )
    return wts

def get_Rnoise_line(conf, args, data, weights=None, sums=None):

    noise0 = conf['simc']['noise']
    factors=array(conf['detrend_factors'])
    target_noises = noise0*factors
    ndiff = target_noises - noise0
    xvals = 2*noise0*ndiff

    if not args.no_Rpsf_noise:
        do_psf=True
    else:
        do_psf=False

    if sums is not None:
        # sum over all shear fields
        ninv = 1.0/sums['n'].sum()
        Rdt = sums['Rdt'].sum(axis=0) * ninv
        Rdt_psf = sums['Rdt_psf'].sum(axis=0) * ninv

    else:
        if weights is not None:
            wsum=weights.sum()

            R = data['mcal_dt_Rnoise']
            Rshape=R.shape[1:]
            Rdt = numpy.zeros(Rshape)


            for i in xrange(Rshape[0]):
                for j in xrange(Rshape[1]):
                    for k in xrange(Rshape[2]):
                        Rdt[i,j,k] = (R[:,i,j,k]*weights).sum()/wsum

            if do_psf:
                Rpsf = data['mcal_dt_Rnoise_psf']
                Rpsf_shape=Rpsf.shape[1:]

                Rdt_psf = numpy.zeros(Rpsf_shape)

                for i in xrange(Rpsf_shape[0]):
                    for j in xrange(Rpsf_shape[1]):
                        Rdt_psf[i,j] = (Rpsf[:,i,j]*weights).sum()/wsum

        else:
            Rdt = data['mcal_dt_Rnoise'].mean(axis=0)

            if do_psf:
                Rdt_psf = data['mcal_dt_Rnoise_psf'].mean(axis=0)

    A = zeros( (2,2) )
    Aerr = zeros( (2,2) )
    Apsf = zeros(2)
    Apsf_err = zeros(2)

    p='%s (%.3g +/- %.3g) + (%.3g +/ %.3g) deltan'
    for i in xrange(2):

        if do_psf:
            res = fitline(xvals, Rdt_psf[:,i])
            Apsf[i] = res['slope']
            Apsf_err[i] = res['slope_err']

            plot_line_fit(
                args,
                'Rnoise-detrend-Rpsf%d' % (i+1),
                xvals, Rdt_psf[:,i],res,
                r'$2 n \Delta n$',
                r'$\Delta R^{PSF}_%d$' % (i+1),
            )

        for j in xrange(2):
            res = fitline(xvals, Rdt[:,i,j])
            A[i,j] = res['slope']
            Aerr[i,j] = res['slope_err']

            n='A[%d,%d]' % (i+1,j+1)
            s=res['slope']
            serr=res['slope_err']
            o=res['offset']
            oerr=res['offset_err']
            print(p % (n,o,oerr,s,serr))

            plot_line_fit(
                args,
                'Rnoise-detrend-R%d%d' % (i+1,j+1),
                xvals, Rdt[:,i,j],res,
                r'$2 n \Delta n$',
                r'$\Delta R_{%d,%d}$' % (i+1,j+1),
            )

    Rnoise = A*noise0**2
    Rnoise_err = Aerr*noise0**2

    Rnoise_psf = Apsf*noise0**2
    Rnoise_psf_err = Apsf_err*noise0**2

    print_Rs(Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err, type='noise')

    return Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err
    #return Rnoise

def print_Rs(R, Rerr, Rpsf, Rpsf_err, type=''):
    p='%s: %.5g +/- %.5g'
    for i in xrange(2):
        n='R%s_psf[%d]' % (type,i+1)
        print(p % (n,Rpsf[i],Rpsf_err[i]))

    for i in xrange(2):
        for j in xrange(2):
            n='R%s[%d,%d]' % (type,(i+1),(j+1))
            print(p % (n,R[i,j],Rerr[i,j]))


def plot_line_fit(args, extra, x, y, res, xlabel, ylabel):
    plt=biggles.FramedPlot()

    ymin=y.min()
    ymax=y.max()
    if ymin < 0:
        yr = [1.1*ymin, 0.0]
    else:
        yr = [0, 1.1*ymax]

    xr = [0.0, 1.1*x.max()]

    plt.xrange=xr
    plt.yrange=yr
    plt.xlabel=xlabel
    plt.ylabel=ylabel
    plt.aspect_ratio=1

    xfit = numpy.linspace(0, xr[1])
    yfit = res['offset'] + res['slope']*xfit

    pts = biggles.Points(x,y,type='filled circle')
    c = biggles.Curve(xfit, yfit, color='blue')

    alab=r'$slope = %.3g \pm %.3g' % (res['slope'],res['slope_err'])
    blab=r'$offset = %.3g \pm %.3g' % (res['offset'],res['offset_err'])
    alabel=biggles.PlotLabel(0.9, 0.9, alab, halign='right')
    blabel=biggles.PlotLabel(0.9, 0.85, blab, halign='right')

    plt.add(c, pts, alabel, blabel)

    plotfile=files.get_plot_url(args.runs[0], extra)

    print("writing:",plotfile)
    eu.ostools.makedirs_fromfile(plotfile)
    plt.write_eps(plotfile)

    if args.show:
        plt.show()

S2N_FACTORS=array([1.1,1.2,1.3])
def get_averages_with_selection(conf, args, data):

    print("getting means")
    means = get_averages(conf, args, data, show_progress=False)
    s2n_vals=S2N_FACTORS*args.min_s2n

    nshear=s2n_vals.size
    diffs = numpy.zeros(means.size,
                            dtype=[('min_s2n','f8',nshear),
                                   ('shear_diff1','f8',nshear)])

    for i,s2n in enumerate(s2n_vals):
        print("    getting means s2n > ",s2n)
        w,=where(data['s2n_r'] > s2n)

        tmeans = get_averages(conf, args, data[w], show_progress=False)

        diffs['min_s2n'][:,i] = s2n_vals[i]
        diffs['shear_diff1'][:,i] = tmeans['shear'][:,0]-means['shear'][:,0]
        diffs['shear_diff2'][:,i] = tmeans['shear'][:,1]-means['shear'][:,1]

    res1 = fitline(
        diffs['min_s2n'].ravel(),
        diffs['shear_diff1'].ravel()
    )
    res2 = fitline(
        diffs['min_s2n'].ravel(),
        diffs['shear_diff2'].ravel()
    )
    fmt = '  M{i}: %.3g +/- %.3g C{i}: %.3g +/- %.3g'.format(i=1)
    print(fmt % (res1['slope'],res1['slope_err'],res1['offset'],res1['offset_err']))
    fmt = '  M{i}: %.3g +/- %.3g C{i}: %.3g +/- %.3g'.format(i=2)
    print(fmt % (res2['slope'],res2['slope_err'],res2['offset'],res2['offset_err']))


def main():
    args = parser.parse_args()

    conf = nsim.files.read_config(args.runs[0])
    conf['simc'] = nsim.files.read_config(conf['sim'])

    summer=Summer(conf, args)
    summer.go()

    fits=reredux.averaging.fit_m_c(summer.means)
    fitsone=reredux.averaging.fit_m_c(summer.means,onem=True)
    doplot(args, summer.means, fits)
    return


    kw={}
    if args.min_s2n is not None:
        kw['min_s2n']=args.min_s2n
    if args.min_logF is not None:
        kw['min_logF']=args.min_logF

    #data=read_data(conf, args, **kw)

    if args.boot_Rnoise:
        get_averages_boot_Rnoise(conf, args, data)
    else:
        #means = get_averages(conf, args, data, show_progress=False)
        means = read_and_average(conf, args)

        fits=reredux.averaging.fit_m_c(means)
        fitsone=reredux.averaging.fit_m_c(means,onem=True)
        doplot(args, means, fits)

main()
