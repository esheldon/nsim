#!/usr/bin/env python
from __future__ import print_function
import sys
import os
from pprint import pprint
import numpy
from numpy import sqrt, array, diag, ones, zeros
from numpy import where, newaxis, exp, log
from numpy import newaxis
import yaml
import biggles

import fitsio

import ngmix
import nsim
from nsim import files
from nsim.averaging import SummerDT

import argparse
import esutil as eu
from esutil.numpy_util import between

import reredux


fclass=argparse.ArgumentDefaultsHelpFormatter
parser=argparse.ArgumentParser(formatter_class=fclass)

parser.add_argument('runs', nargs='+',help='run to use in fit')

parser.add_argument('--select',default=None,
                    help='string for selection, refer to data[field] etc.')
parser.add_argument('--select-from',default=None,
                    help='read the selection from the given yaml file')
parser.add_argument('--reflect',action='store_true',
                    help='reflect e1,e2 for select/weights corrections')

parser.add_argument('--nrand',type=int,default=1,
                    help=('number of times to randomize for '
                          'selection/weighting corrections'))

parser.add_argument('--ntest',default=None,type=int,
                    help='work on a small subset for quick tests')

parser.add_argument('--nocorr',action='store_true',
                    help='do not apply correlated noise correction')
parser.add_argument('--nocorr-select',action='store_true',
                    help='do not apply corrections for the selection')

parser.add_argument('--boot',action='store_true',
                    help='bootstrap over fields')

parser.add_argument('--boot-Rnoise',action='store_true')
parser.add_argument('--nboot-Rnoise',type=int,default=100)
parser.add_argument('--bootsize-Rnoise',type=int,default=1000000)

parser.add_argument('--weights',default=None,help='type of weight to use')
parser.add_argument('--s2n-soft',type=float,default=10.0)
parser.add_argument('--shapenoise',type=float,default=0.20)

parser.add_argument('--no-Rpsf-noise',action='store_true')

parser.add_argument('--show',action='store_true',help='show plot')
parser.add_argument('--yrange', help="yrange of plot")
parser.add_argument('--xrange', help="xrange of plot")

parser.add_argument('--fit-only',action='store_true',
                    help='get the means from the written file')

default_columns=[
    'shear_index',
    'mcal_g',
    'mcal_gpsf',
    'mcal_R',
    'mcal_Rpsf',
    'mcal_dt_Rnoise',
    'mcal_dt_Rnoise_psf',
]

cache_columns=[
    'shear_index',
    'pars',
    's2n_r',
    'mcal_g',
    'mcal_gpsf',
    'mcal_R',
    'mcal_Rpsf',
    'mcal_dt_Rnoise',
    'mcal_dt_Rnoise_psf',
]

def get_subset(conf, args, fname, **kw):

    docuts=False
    types=['min_s2n','min_logF']
    for t in types:
        if kw[t] is not None:
            docuts=True

    if not docuts:
        return None

    with fitsio.FITS(fname) as fobj:
        nrows = fobj[1].get_nrows()
        logic = numpy.ones(nrows,dtype=bool)

        if kw['min_s2n'] is not None:
            print("making s2n cut:",kw['min_s2n'])

            columns=['s2n_r']
            print("reading cut fields only:",columns)
            t=fitsio.read(fname, columns=columns)

            logic = logic & (t['s2n_r'] > kw['min_s2n'])

        if kw['min_logF'] is not None:
            print("making logF cut:",kw['min_logF'])

            columns=['pars']
            print("reading cut fields only:",columns)
            t=fitsio.read(fname, columns=columns)

            logic = logic & (t['pars'][:,5] > kw['min_logF'])

    w,=numpy.where(logic)
    print("    kept: %d/%d" % (w.size,logic.size))

    return w

def get_cache_file(runs):

    rlist='-'.join(runs)
    rlist=rlist.replace('run-','')

    tdir=os.environ['TMPDIR']
    tfile= nsim.files.get_output_url(runs[0], 0, 0)
    tfile=os.path.basename(tfile)

    tfile=tfile.replace(runs[0], rlist)
    tfile=os.path.join(tdir, tfile)
    return tfile

def count_objects(flist):

    n=0
    for fname in flist:
        with fitsio.FITS(fname) as fits:
            n += fits[1].get_nrows()

    return n

def cache_in_chunks(runs, columns, cache_file):

    print("cacheing columns:")
    pprint(columns)

    chunksize=1000000

    first=True
    with fitsio.FITS(cache_file,'rw',clobber=True) as output:
        for run in runs:

            fname = nsim.files.get_output_url(run, 0, 0)
            print(fname)

            with fitsio.FITS(fname) as fits:

                hdu=fits[1]

                nrows=hdu.get_nrows()
                nchunks = nrows//chunksize

                if (nrows % chunksize) > 0:
                    nchunks += 1

                beg=0
                for i in xrange(nchunks):
                    print("    chunk %d/%d" % (i+1,nchunks))

                    end=beg+chunksize

                    data = hdu[columns][beg:end]

                    if first:
                        output.write(data)
                        first=False
                    else:
                        output[-1].append(data)

                    beg = beg + chunksize

def read_data(conf, args, **kw):

    columns = default_columns
    ccolumns = cache_columns

    if args.no_Rpsf_noise:
        columns=[c for c in columns if c != 'mcal_dt_Rnoise_psf']
        ccolumns=[c for c in ccolumns if c != 'mcal_dt_Rnoise_psf']

    cache_file=get_cache_file(args.runs)
    print("cache file:",cache_file)

    if not os.path.exists(cache_file):
        cache_in_chunks(args.runs, ccolumns, cache_file)

    print("reading cache:",cache_file)

    if len(kw) > 0:
        print("getting subset")
        rows=get_subset(conf, args, cache_file, **kw)
    elif args.ntest is not None:
        rows=numpy.arange(args.ntest)
        print("reading",rows.size,"rows")
    else:
        print("reading all")
        rows=None

    #rows=numpy.arange(1000000)
    #data=fitsio.read(cache_file,columns=columns,rows=rows)
    data=fitsio.read(cache_file,rows=rows)

    return data



SIGMA2_MIN_CONSTANT_GROUND = 4.     # 2**2
NORMALIZATION_CONSTANT_SPACE = 1.232
NORMALIZATION_CONSTANT_GROUND = NORMALIZATION_CONSTANT_SPACE

CFID = 2.e-4
MFID = 2.e-3

def fitpoly(noise0, noises, Rdiff, Rdiff_err):
    fitter=Fitter(noise0, noises, Rdiff, Rdiff_err)
    fitter.dofit()
    #print(fitter)
    if False:
        fitter.plot(show=True)
        if raw_input('hit a key: ')=='q':
            stop

    res=fitter.get_result()
    return res

def fitpolyold(n0, noises, R0, R0err, Rnoise, Rnoise_err):
    ntot = noises.size + 1

    noise_tot = zeros(ntot)
    noise_tot[0] = n0
    noise_tot[1:] = noises

    Rtot = zeros(ntot)
    Rtot_err = zeros(ntot)
    Rtot[0] = R0
    Rtot[1:] = Rnoise
    Rtot_err[0] = R0err
    Rtot_err[1:] = Rnoise_err
    
    if True:
        biggles.plot(noise_tot, Rtot)
        stop

    fitter=Fitter(noise_tot, Rtot, Rtot_err)
    fitter.dofit()
    print(fitter)

    res=fitter.get_result()
    R = res['pars'][0]
    Rerr = res['perr'][0]

    return R, Rerr


class Fitter(object):
    def __init__(self, x0, x, y, yerr):

        self.x0=x0
        self.x=x

        self.xdiff=x-x0
        self.x2diff=x**2 - x0**2
        self.y=y
        self.yerr=yerr

        self.npars=2

        self._set_guess()

    def get_result(self):
        return self._result

    def dofit(self):
        from scipy.optimize import leastsq
        res=leastsq(self._errfunc, self.guess, full_output=1)

        pars, pcov0, infodict, errmsg, ier = res
        if ier == 0:
            # wrong args, this is a bug
            raise ValueError(errmsg)

        numiter = infodict['nfev']
        pcov=None
        perr=None

        if pcov0 is not None:
            pcov = self._scale_leastsq_cov(pars, pcov0)

            d=numpy.diag(pcov)
            w,=numpy.where(d < 0)

            if w.size == 0:
                # only do if non negative
                perr = numpy.sqrt(d)

        self._result={'pars':pars, 'pcov':pcov, 'perr':perr,'errmsg':errmsg}


    def _set_guess(self):
        """
        [a, b]
        a (x^2 - x0^2) + b (x-x0)
        """
        self.guess = array([-0.1, 0.1])

    def eval_pars(self, pars, x=None):
        """
        [a, b]
        a (x^2 - x0^2) + b (x-x0)
        """

        if x is not None:
            xdiff=x-self.x0
            x2diff=x**2 - self.x0**2
        else:
            xdiff=self.xdiff
            x2diff=self.x2diff

        return pars[0]*x2diff + pars[1]*xdiff

    def _errfunc(self, pars):
        model = self.eval_pars(pars)
        diff = (model-self.y)/self.yerr
        return diff.ravel()

    def _scale_leastsq_cov(self, pars, pcov):
        """
        Scale the covariance matrix returned from leastsq; this will
        recover the covariance of the parameters in the right units.
        """

        # is total size right here?
        dof = (self.y.size-len(pars))
        s_sq = (self._errfunc(pars)**2).sum()/dof
        return pcov * s_sq 

    def plot(self, show=False):
        import biggles
        pars=self._result['pars']
        perr=self._result['perr']

        x=numpy.linspace(self.x0, self.x.max(),100)
        x2diff=x**2 - self.x0**2
        yfit = self.eval_pars(pars, x=x)

        plt=biggles.FramedPlot()

        pts=biggles.Points(self.x2diff, self.y)
        err=biggles.SymmetricErrorBarsY(self.x2diff, self.y, self.yerr)

        c=biggles.Curve(x2diff, yfit, type='solid', color='blue')

        plt.add(c, pts, err)

        alab=r'$A = %.3g \pm %.3g' % (pars[0], perr[0])
        blab=r'$B = %.3g \pm %.3g' % (pars[1], perr[1])
        alabel=biggles.PlotLabel(0.9, 0.9, alab, halign='right')
        blabel=biggles.PlotLabel(0.9, 0.85, blab, halign='right')

        plt.add(alabel, blabel)

        if show:
            plt.show()
        return plt



    def __repr__(self):
        if hasattr(self,'_result'):
            pars=self._result['pars']
            perr=self._result['perr']

            rep = """
    a (x^2-x0^2) + b (x-x0)
    a: %g +/- %g
    b: %g +/- %g\n""" % (pars[0],perr[0],pars[1],perr[1])

        return rep



class FitterOld(object):
    def __init__(self, x, y, yerr):

        self.x=x

        self.xsq=x**2
        self.diffx = x - x[0]

        self.y=y
        self.yerr=yerr

        self.npars=2

        self._set_guess()

    def get_result(self):
        return self._result

    def dofit(self):
        from scipy.optimize import leastsq
        res=leastsq(self._errfunc, self.guess, full_output=1)

        pars, pcov0, infodict, errmsg, ier = res
        if ier == 0:
            # wrong args, this is a bug
            raise ValueError(errmsg)

        numiter = infodict['nfev']
        pcov=None
        perr=None

        if pcov0 is not None:
            pcov = self._scale_leastsq_cov(pars, pcov0)

            d=numpy.diag(pcov)
            w,=numpy.where(d < 0)

            if w.size == 0:
                # only do if non negative
                perr = numpy.sqrt(d)

        self._result={'pars':pars, 'pcov':pcov, 'perr':perr}


    def _set_guess(self):
        """
        [R, a, b]
        R +  a (x-x0) + b x^2
        """
        self.guess = array([0.5, 0.1, -0.1])

    def eval_pars(self, pars):
        """
        [R, a, b]
        R +  a (x-x0) + b x^2
        """

        return pars[0] + pars[1]*self.diffx + pars[2]*self.xsq

    def _errfunc(self, pars):
        model = self.eval_pars(pars)
        diff = (model-self.y)/self.yerr
        return diff.ravel()

    def _scale_leastsq_cov(self, pars, pcov):
        """
        Scale the covariance matrix returned from leastsq; this will
        recover the covariance of the parameters in the right units.
        """

        # is total size right here?
        dof = (self.x.size-len(pars))
        s_sq = (self._errfunc(pars)**2).sum()/dof
        return pcov * s_sq 

    def __call__(self, x):
        """
        pars order same as for numpy.poly1d
        """
        return self.eval_pars(self._result['pars'])

    def __repr__(self):
        if hasattr(self,'_result'):
            pars=self._result['pars']
            perr=self._result['perr']

            rep = """
    R + a dx + b x^2
    R: %g +/- %g
    a: %g +/- %g
    b: %g +/- %g\n""" % (pars[0],perr[0],pars[1],perr[1],pars[2],perr[2])

        return rep



# quick line fit pulled from great3-public code
def _calculateSvalues(xarr, yarr, sigma2=1.):
    """Calculates the intermediate S values required for basic linear regression.

    See, e.g., Numerical Recipes (Press et al 1992) Section 15.2.
    """
    if len(xarr) != len(yarr):
        raise ValueError("Input xarr and yarr differ in length!")
    if len(xarr) <= 1:
        raise ValueError("Input arrays must have 2 or more values elements.")

    S = len(xarr) / sigma2
    Sx = numpy.sum(xarr / sigma2)
    Sy = numpy.sum(yarr / sigma2)
    Sxx = numpy.sum(xarr * xarr / sigma2)
    Sxy = numpy.sum(xarr * yarr / sigma2)
    return (S, Sx, Sy, Sxx, Sxy)

def fitline(xarr, yarr):
    """Fit a line y = a + b * x to input x and y arrays by least squares.

    Returns the tuple (a, b, Var(a), Cov(a, b), Var(b)), after performing an internal estimate of
    measurement errors from the best-fitting model residuals.

    See Numerical Recipes (Press et al 1992; Section 15.2) for a clear description of the details
    of this simple regression.
    """
    # Get the S values (use default sigma2, best fit a and b still valid for stationary data)
    S, Sx, Sy, Sxx, Sxy = _calculateSvalues(xarr, yarr)
    # Get the best fit a and b
    Del = S * Sxx - Sx * Sx
    a = (Sxx * Sy - Sx * Sxy) / Del
    b = (S * Sxy - Sx * Sy) / Del
    # Use these to estimate the sigma^2 by residuals from the best-fitting model
    ymodel = a + b * xarr
    sigma2 = numpy.mean((yarr - ymodel)**2)
    # And use this to get model parameter error estimates
    var_a  = sigma2 * Sxx / Del
    cov_ab = - sigma2 * Sx / Del
    var_b  = sigma2 * S / Del

    a_err = numpy.sqrt(var_a)
    b_err = numpy.sqrt(var_b)

    return {'offset':a,
            'offset_err':a_err,
            'slope':b,
            'slope_err':b_err,
            'cov':cov_ab}
    #return a, a_err, b, b_err, cov_ab

def fitline_zero_offset(x, y):

    # Our model is y = a * x, so things are quite simple, in this case...
    # x needs to be a column vector instead of a 1D vector for this, however.
    x = x[:,numpy.newaxis]
    a, _, _, _ = numpy.linalg.lstsq(x, y)

    return {'offset':0.0,
            'offset_err':0.0,
            'slope':a[0],
            'slope_err':0.0}
    
def calc_q(fits):

    m1=fits['m'][0,0]
    m2=fits['m'][0,1]
    c1=fits['c'][0,0]
    c2=fits['c'][0,1]

    sigma2_min = SIGMA2_MIN_CONSTANT_GROUND 
    norm = NORMALIZATION_CONSTANT_GROUND 

    num = 2000.0 * norm
    denom = numpy.sqrt(  (c1 / CFID)**2 
                       + (c2 / CFID)**2
                       + (m1 / MFID)**2
                       + (m2 / MFID)**2
                       + sigma2_min)

    Q = num/denom
    
    print("  Q: %g" % Q)

    return Q

def doplot(args, data, fits):
    import biggles

    #Q=calc_q(fits)

    extra=['fit-m-c']
    if len(args.runs) > 1:
        extra = args.runs[1:] + extra
    extra = '-'.join(extra)

    if args.yrange is not None:
        yrange=[float(r) for r in args.yrange.split(',')]
    else:
        yrange=[-0.01,0.01]

    xrng=args.xrange
    if xrng is not None:
        xrng=[float(r) for r in args.xrange.split(',')]

    tab=biggles.Table(1,2)
    tab.aspect_ratio=0.5

    diff = data['shear'] - data['shear_true']

    plts=[]
    for i in [0,1]:

        x = data['shear_true'][:,i]
        plt =biggles.plot(
            x,
            diff[:,i],
            xlabel='shear%d true' % (i+1,),
            ylabel='shear%d diff' % (i+1,),
            yrange=yrange,
            xrange=xrng,
            visible=False,
        )
        yfit=fits['m'][0,i]*x + fits['c'][0,i]

        z=biggles.Curve(x, x*0, color='black')
        c=biggles.Curve(x, yfit, color='red')
        plt.add(z,c)

        mstr='m%d: %.2g +/- %.2g' % (i+1,fits['m'][0,i],fits['merr'][0,i])
        cstr='c%d: %.2g +/- %.2g' % (i+1,fits['c'][0,i],fits['cerr'][0,i])
        mlab=biggles.PlotLabel(0.1,0.9,
                               mstr,
                               halign='left')
        clab=biggles.PlotLabel(0.1,0.85,
                               cstr,
                               halign='left')
        plt.add(mlab,clab)
        if False and i==0:
            Qstr='Q: %d' % (int(Q),)
            Qlab=biggles.PlotLabel(0.1,0.8,
                                   Qstr,
                                   halign='left')
            plt.add(Qlab)


        tab[0,i] = plt

    fname=files.get_plot_url(args.runs[0], extra)
    eu.ostools.makedirs_fromfile(fname)
    print("writing:",fname)
    tab.write_eps(fname)

    if args.show:
        tab.show(width=1000, height=1000)

def get_mean_struct(n):
    dt=[('shear','f8',2),
        ('shear_true','f8',2),
        ('shear_err','f8',2)]

    means = numpy.zeros(n, dtype=dt)
    return means

def get_boot_struct(nboot):
    dt=[('m','f8',2),
        ('c','f8',2)]

    bs = numpy.zeros(nboot, dtype=dt)
    return bs

def read_means(args):
    return reredux.files.read_fit_file(args.run,
                                       extra='shear-means')
def write_means(args, means):
    fname=reredux.files.get_fit_file(args.run,
                                     extra='shear-means')
    eu.ostools.makedirs_fromfile(fname)

    print("writing:",fname)
    fitsio.write(fname, means, clobber=True)


def print_shear(ind, num, shear, shear_err):
    mess="  %d: %d  %g +/- %g  %g +/- %g"
    tup=(ind, num, shear[0],shear_err[0], shear[1],shear_err[1])
    print(mess % tup)


def add_fake_shear(conf, args, data, Rnoise, Rnoise_sel, index, shear):
    """
    add shear using the individual R values
    """
    g = data['mcal_g']
    R = data['mcal_R']

    R11 = R[:,0,0].copy()
    R22 = R[:,1,1].copy()
    R11_sel = R[index,0,0].copy()
    R22_sel = R[index,1,1].copy()

    R11 -= Rnoise[0,0]
    R22 -= Rnoise[1,1]
    R11_sel -= Rnoise_sel[0,0]
    R22_sel -= Rnoise_sel[1,1]

    g1 = g[:,0] - g[:,0].mean()
    g2 = g[:,1] - g[:,1].mean()

    print("making sheared")
    sg1,junk = ngmix.shape.shear_reduced(g1,
                                         g2,
                                         shear*R11,
                                         0.0)
    junk,sg2 = ngmix.shape.shear_reduced(g1,
                                         g2,
                                         0.0,
                                         shear*R22)

    sg1_sel,junk = ngmix.shape.shear_reduced(g1[index],
                                             g2[index],
                                             shear*R11_sel,
                                             0.0)
    junk,sg2_sel = ngmix.shape.shear_reduced(g1[index],
                                             g2[index],
                                             0.0,
                                             shear*R22_sel)

    return sg1, sg2, sg1_sel, sg2_sel

def do_sums1(nshear, data, args, sums=None, select=None):

    n_detrend = data['mcal_dt_Rnoise'].shape[1]

    h,rev = eu.stat.histogram(data['shear_index'],
                              min=0,
                              max=nshear-1,
                              rev=True)
    nind = h.size
    assert nshear==nind

    if sums is None:
        dt=[
            ('n','i8'),
            ('g','f8',2),
            ('gpsf','f8',2),
            ('R','f8',(2,2)),
            ('Rpsf','f8',2),
            ('Rdt','f8',(n_detrend,2,2)),
            ('Rdt_psf','f8',(n_detrend,2)),
        ]

        sums=numpy.zeros(nshear, dtype=dt)

    for i in xrange(nshear):
        if rev[i] != rev[i+1]:
            w=rev[ rev[i]:rev[i+1] ]

            t=data[w]

            if select is not None:
                logic=eval(select)
                w,=numpy.where(logic)
                print("        keeping %d/%d from cuts" % (w.size,t.size))
                t=t[w]

            sums['n'][i] += w.size
            sums['g'][i] += t['mcal_g'].sum(axis=0)
            sums['gpsf'][i] += t['mcal_gpsf'].sum(axis=0)

            sums['R'][i] += t['mcal_R'].sum(axis=0)
            sums['Rpsf'][i] += t['mcal_Rpsf'].sum(axis=0)

            if not args.nocorr:

                sums['Rdt'][i] += t['mcal_dt_Rnoise'].sum(axis=0)

                if not args.no_Rpsf_noise:
                    sums['Rdt_psf'][i] += t['mcal_dt_Rnoise_psf'].sum(axis=0)

    return sums

def do_sums(conf, args, fake_dict=None):

    sconf=conf['simc']
    shears = sconf['shear']['shears']
    nshear=len(shears)

    chunksize=1000000
    sums=None
    sums_select=None
    ntot=0
    for run in args.runs:
        if args.ntest is not None and ntot > args.ntest:
            break

        fname = nsim.files.get_output_url(run, 0, 0)
        print(fname)
        with fitsio.FITS(fname) as fits:

            hdu=fits[1]

            nrows=hdu.get_nrows()
            nchunks = nrows//chunksize

            if (nrows % chunksize) > 0:
                nchunks += 1

            beg=0
            for i in xrange(nchunks):
                print("    chunk %d/%d" % (i+1,nchunks))

                end=beg+chunksize

                data = hdu[beg:end]
                ntot += data.size

                sums=do_sums1(nshear, data, args, sums=sums)
                if args.select is not None:
                    sums_select=do_sums1(nshear, data, args, sums=sums_select,
                                         select=args.select)

                beg = beg + chunksize

                if args.ntest is not None and ntot > args.ntest:
                    break
    return sums, sums_select

def read_and_average(conf, args):

    sconf=conf['simc']
    shears = sconf['shear']['shears']
    nshear=len(shears)

    sums, sums_select = do_sums(conf, args)

    # convert to averages
    ntot=sums['n'].sum()
    R = sums['R'].sum(axis=0)/ntot
    Rpsf = sums['Rpsf'].sum(axis=0)/ntot

    if not args.nocorr:
        Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                get_Rnoise_line(conf, args, None, sums=sums)

        R -= Rnoise
        Rpsf -= Rnoise_psf

        if sums_select is not None:
            ntot_sel =sums_select['n'].sum()
            R_sel = sums_select['R'].sum(axis=0)/ntot_sel
            Rpsf_sel = sums_select['Rpsf'].sum(axis=0)/ntot_sel

            Rnoise_sel, terr, Rnoise_psf_sel, terr = \
                    get_Rnoise_line(conf, args, None, sums=sums_select)

            R_sel -= Rnoise_sel
            Rpsf_sel -= Rnoise_psf_sel

    if sums_select is not None:
        # using the mean R values
        sel = get_selection_effect(conf, args, R_noise, Rnoise_sel)
        sums_no_select=sums
        sums=sums_select

    g = sums['g']
    gpsf = sums['gpsf']

    ninv = 1.0/sums['n']
    g[:,0]    *= ninv
    g[:,1]    *= ninv
    gpsf[:,0] *= ninv
    gpsf[:,1] *= ninv

    Rinv = numpy.linalg.inv(R)

    means=get_mean_struct(nshear)

    for i in xrange(nshear):

        shear_true = shears[i]

        psf_corr  = Rpsf*gpsf[i]

        gmean     = g[i]
        shear     = numpy.dot(Rinv, gmean-psf_corr)

        means['shear'][i] = shear
        means['shear_err'][i] = 1.0
        means['shear_true'][i] = shear_true

    return means



def get_averages(conf, args, data, show_progress=True):

    if args.weights:
        return get_averages_weighted(conf, args, data,
                                     show_progress=show_progress)

    sconf=conf['simc']
    shears = sconf['shear']['shears']

    print("histogramming shear index")
    h,rev = eu.stat.histogram(data['shear_index'], rev=True)
    nind = h.size

    print("Getting overall means")
    g=data['mcal_g']
    gpsf=data['mcal_gpsf']

    R=data['mcal_R']
    Rpsf=data['mcal_Rpsf']

    Rmean = R.mean(axis=0)
    Rerr = R.std(axis=0)/sqrt(R.shape[0])

    Rpsf_mean = Rpsf.mean(axis=0)
    Rpsf_err = Rpsf.std(axis=0)/sqrt(R.shape[0])

    if not args.nocorr:
        print("calculating detrend correlated noise corrections")
        Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                get_Rnoise_line(conf, args, data)

        Rmean -= Rnoise
        Rpsf_mean -= Rnoise_psf

        Rerr = sqrt(Rerr**2 + Rnoise_err**2)
        Rpsf_err = sqrt(Rpsf_err**2 + Rnoise_psf_err**2)
    else:
        print("skipping correlated noise correction")

    Rinv = numpy.linalg.inv(Rmean)


    print_Rs(Rmean, Rerr, Rpsf_mean, Rpsf_err)

    means=get_mean_struct(nind)

    #psf_corr  = Rpsf_mean*gpsf.mean(axis=0)

    print("getting shear field means")
    for i in xrange(nind):
        if show_progress:
            print("shear index:",i)

        w=rev[ rev[i]:rev[i+1] ]

        shear_true = shears[i]

        psf_corr  = Rpsf_mean*gpsf[w].mean(axis=0)

        gmean     = g[w].mean(axis=0)
        shear     = numpy.dot(Rinv, gmean-psf_corr)
        shear_err = g[w].std(axis=0)/numpy.sqrt(w.size)
        shear_err = numpy.dot(Rinv, shear_err)

        means['shear'][i] = shear
        means['shear_err'][i] = shear_err
        means['shear_true'][i] = shear_true

    return means

def get_averages_weighted(conf, args, data, show_progress=True):

    print("using weights")
    weights=get_s2n_weights(data['s2n_r'], args)
    wsum=weights.sum()
    #wna1=weights[:,newaxis]
    #wna2=weights[:,newaxis,newaxis]

    sconf=conf['simc']
    shears = sconf['shear']['shears']

    h,rev = eu.stat.histogram(data['shear_index'], rev=True)
    nind = h.size

    g=data['mcal_g']
    gpsf=data['mcal_gpsf']

    R=data['mcal_R']
    Rpsf=data['mcal_Rpsf']

    print("getting Rnoise")
    Rnoise, Rnoise_psf = get_Rnoise_line(conf, args, data, weights=weights)
    #Rnoise = get_Rnoise_line(conf, args, data, weights=weights)

    print("calculating Rmean")
    Rmean = numpy.zeros( (2,2) )
    Rpsf_mean = numpy.zeros(2)
    for i in xrange(2):
        Rpsf_mean[i] = (Rpsf[:,i]*weights).sum()/wsum
        for j in xrange(2):
            Rmean[i,j] = (R[:,i,j]*weights).sum()/wsum

    Rmean = Rmean - Rnoise
    Rpsf_mean = Rpsf_mean - Rnoise_psf

    Rinv = numpy.linalg.inv(Rmean)

    means=get_mean_struct(nind)

    print("getting shears for each shear_index")
    gmean=numpy.zeros(2)
    psf_corr=numpy.zeros(2)
    for i in xrange(nind):
        if show_progress:
            print("shear index:",i)

        w=rev[ rev[i]:rev[i+1] ]

        shear_true = shears[i]

        twsum = weights[w].sum()
        for j in xrange(2):
            psf_corr[j]  = Rpsf_mean[j]*(gpsf[w,j]*weights[w]).sum()/twsum
            gmean[j]     = (g[w,j]*weights[w]).sum()/twsum

        shear = numpy.dot(Rinv, gmean-psf_corr)

        # wrong, but won't get used anyway
        shear_err = g[w].std(axis=0)/numpy.sqrt(w.size)
        shear_err = numpy.dot(Rinv, shear_err)

        means['shear'][i] = shear
        means['shear_err'][i] = shear_err
        means['shear_true'][i] = shear_true

    return means

def get_averages_boot_Rnoise(conf, args, data):

    sconf=conf['simc']
    shears = sconf['shear']['shears']

    g=data['mcal_g']
    gpsf=data['mcal_gpsf']

    R=data['mcal_R']
    Rpsf=data['mcal_Rpsf']

    Rmean0 = R.mean(axis=0)
    Rerr0 = R.std(axis=0)/sqrt(R.shape[0])

    Rpsf_mean0 = Rpsf.mean(axis=0)
    Rpsf_err0 = Rpsf.std(axis=0)/sqrt(R.shape[0])

    bs=get_boot_struct(args.nboot_Rnoise)


    h,rev = eu.stat.histogram(data['shear_index'], rev=True)
    nind = h.size

    g_means = []
    g_errs = []
    gpsf_means = []
    for i in xrange(nind):
        w=rev[ rev[i]:rev[i+1] ]

        gmean     = g[w].mean(axis=0)
        g_err = g[w].std(axis=0)/numpy.sqrt(w.size)
        gpsf_mean = gpsf[w].mean(axis=0)

        g_means.append(gmean)
        g_errs.append(g_err)
        gpsf_means.append(gpsf_mean)



    means=get_mean_struct(nind)
    for iboot in xrange(args.nboot_Rnoise):

        print("%d/%d" % (iboot+1,args.nboot_Rnoise))

        subset=numpy.random.randint(
            0,
            data.size,
            args.bootsize_Rnoise
        )

        Rnoise, Rnoise_err, Rnoise_psf, Rnoise_psf_err = \
                get_Rnoise_line(conf, args, data[subset])

        Rmean = Rmean0 - Rnoise
        Rpsf_mean = Rpsf_mean0 - Rnoise_psf
        Rinv = numpy.linalg.inv(Rmean)

        Rerr = sqrt(Rerr0**2 + Rnoise_err**2)
        Rpsf_err = sqrt(Rpsf_err0**2 + Rnoise_psf_err**2)

        print_Rs(Rmean, Rerr, Rpsf_mean, Rpsf_err)

        for i in xrange(nind):

            shear_true = shears[i]

            g_mean = g_means[i]
            g_err = g_errs[i]
            gpsf_mean = gpsf_means[i]

            psf_corr  = gpsf_mean*Rpsf_mean

            shear     = numpy.dot(Rinv, g_mean-psf_corr)
            shear_err = g_err
            shear_err = numpy.dot(Rinv, shear_err)

            means['shear'][i] = shear
            means['shear_err'][i] = shear_err
            means['shear_true'][i] = shear_true

        fits=reredux.averaging.fit_m_c(means)
        bs['m'][iboot] = fits['m'][0,:]
        bs['c'][iboot] = fits['c'][0,:]

    mres = eu.stat.get_stats(bs['m'])
    cres = eu.stat.get_stats(bs['c'])

    print('-'*70)
    for i in xrange(2):
        print_m_c(i+1,
                  mres['mean'][i],
                  mres['err'][i],
                  cres['mean'][i],
                  cres['err'][i])



def print_m_c(sindex, m, merr, c, cerr, r=None):

    fmt = '  m{i}: %.3e +/- %.3e c{i}: %.3e +/- %.3e'.format(i=sindex)
    if r is not None:
        fmt += '  r{i}: %.3g'.format(i=sindex)
        print(fmt % (m, merr, c, cerr,r))
    else:
        print(fmt % (m, merr, c, cerr))

def fit_m_c(data, doprint=True, onem=False):
    strue = data['shear_true']
    sdiff = data['shear'] - data['shear_true']
    serr  = data['shear_err']

    if onem:
        import reredux
        fits=numpy.zeros(1, dtype=[('m','f8'),
                                   ('merr','f8'),
                                   ('c1','f8'),
                                   ('c1err','f8'),
                                   ('c2','f8'),
                                   ('c2err','f8')])


        fitter=reredux.averaging.MCFitter(strue, sdiff, serr)
        fitter.dofit()
        res=fitter.get_result()

        pars=res['pars']
        perr=res['perr']
        fits['m'] = pars[0]
        fits['c1'] = pars[1]
        fits['c2'] = pars[2]
        fits['merr'] = perr[0]
        fits['c1err'] = perr[1]
        fits['c2err'] = perr[2]

        fmt = '  m: %.3e +/- %.3e c1: %.3e +/- %.3e c2: %.3e +/- %.3e'
        print(fmt % (pars[0],perr[0],
                     pars[1],perr[1],
                     pars[2],perr[2]))
        return fits

    fits=numpy.zeros(1, dtype=[('m','f8',2),
                               ('merr','f8',2),
                               ('c','f8',2),
                               ('cerr','f8',2),
                               ('r','f8',2)])
    for i in [0,1]:
        res = fitline(strue[:,i], sdiff[:,i])
        r = res['cov']/sqrt(res['slope_err']**2 * res['offset_err']**2)
        fits['m'][0,i] = res['slope']
        fits['merr'][0,i] = res['slope_err']
        fits['c'][0,i] = res['offset']
        fits['cerr'][0,i] = res['offset_err']
        fits['r'][0,i] = r

        if doprint:
            print_m_c(i+1, res['slope'],res['slope_err'],
                      res['offset'],res['offset_err'], r=r)

    return fits




S2N_FACTORS=array([1.1,1.2,1.3])
def get_averages_with_selection(conf, args, data):

    print("getting means")
    means = get_averages(conf, args, data, show_progress=False)
    s2n_vals=S2N_FACTORS*args.min_s2n

    nshear=s2n_vals.size
    diffs = numpy.zeros(means.size,
                            dtype=[('min_s2n','f8',nshear),
                                   ('shear_diff1','f8',nshear)])

    for i,s2n in enumerate(s2n_vals):
        print("    getting means s2n > ",s2n)
        w,=where(data['s2n_r'] > s2n)

        tmeans = get_averages(conf, args, data[w], show_progress=False)

        diffs['min_s2n'][:,i] = s2n_vals[i]
        diffs['shear_diff1'][:,i] = tmeans['shear'][:,0]-means['shear'][:,0]
        diffs['shear_diff2'][:,i] = tmeans['shear'][:,1]-means['shear'][:,1]

    res1 = fitline(
        diffs['min_s2n'].ravel(),
        diffs['shear_diff1'].ravel()
    )
    res2 = fitline(
        diffs['min_s2n'].ravel(),
        diffs['shear_diff2'].ravel()
    )
    fmt = '  M{i}: %.3g +/- %.3g C{i}: %.3g +/- %.3g'.format(i=1)
    print(fmt % (res1['slope'],res1['slope_err'],res1['offset'],res1['offset_err']))
    fmt = '  M{i}: %.3g +/- %.3g C{i}: %.3g +/- %.3g'.format(i=2)
    print(fmt % (res2['slope'],res2['slope_err'],res2['offset'],res2['offset_err']))


def main():
    args = parser.parse_args()

    conf = nsim.files.read_config(args.runs[0])
    conf['simc'] = nsim.files.read_config(conf['sim'])

    summer=SummerDT(conf, args)
    summer.go()

    summer.plot_fits()
    summer.plot_resid_hist()

    return

main()
